#
# langtag.py
# ==========
#
# Python-3 utilities for working with language tags.
#
# See the Langtag specification for further information. 
#

import json

#
# Exceptions
# ----------
#
# Each exception overloads the __str__ operator so that it can be
# printed as a user-friendly error message.  It has punctuation at the
# end, but it does NOT have a line break at the end.
#
# All exceptions defined by this module are subclasses of LangtagError.
#

class LangtagError(Exception):
  def __str__(self):
    return 'Unknown langtag error!'

class EmbeddedParsingError(LangtagError):
  def __str__(self):
    return 'Error parsing the langtag embedded data files!'

class LogicError(LangtagError):
  def __str__(self):
    return 'Logic error within langtag module!'

#
# Embedded data tables
# --------------------
#
# These are auto-generated from utility programs.  Do not modify them
# directly.
#

# The embedded remap table dictionary.
#
# This is generated by the tagremap utility program from the subtag
# registry data file.  It is a string literal that stores a JSON object.
#
# After the literal data declaration below, the value data_remap will
# be parsed into a dictionary that maps string keys to string values.
#
# If the parsing fails, None will be stored in data_remap.  Functions
# that make use of this embedded table will then raise
# EmbeddedParsingError.
#
# BEGIN AUTO-GENERATED CODE:
data_remap = r'''{
  "art-lojban": "jbo",
  "en-GB-oed": "en-GB-oxendict",
  "i-ami": "ami",
  "i-bnn": "bnn",
  "i-hak": "hak",
  "i-klingon": "tlh",
  "i-lux": "lb",
  "i-navajo": "nv",
  "i-pwn": "pwn",
  "i-tao": "tao",
  "i-tay": "tay",
  "i-tsu": "tsu",
  "no-bok": "nb",
  "no-nyn": "nn",
  "sgn-BE-FR": "sfb",
  "sgn-BE-NL": "vgt",
  "sgn-CH-DE": "sgg",
  "zh-guoyu": "cmn",
  "zh-hakka": "hak",
  "zh-min-nan": "nan",
  "zh-xiang": "hsn",
  "sgn-BR": "bzs",
  "sgn-CO": "csn",
  "sgn-DE": "gsg",
  "sgn-DK": "dsl",
  "sgn-ES": "ssp",
  "sgn-FR": "fsl",
  "sgn-GB": "bfi",
  "sgn-GR": "gss",
  "sgn-IE": "isg",
  "sgn-IT": "ise",
  "sgn-JP": "jsl",
  "sgn-MX": "mfs",
  "sgn-NI": "ncs",
  "sgn-NL": "dse",
  "sgn-NO": "nsl",
  "sgn-PT": "psr",
  "sgn-SE": "swl",
  "sgn-US": "ase",
  "sgn-ZA": "sfs",
  "zh-cmn": "cmn",
  "zh-cmn-Hans": "cmn-Hans",
  "zh-cmn-Hant": "cmn-Hant",
  "zh-gan": "gan",
  "zh-wuu": "wuu",
  "zh-yue": "yue"
}'''
# END AUTO-GENERATED CODE.
try:
  data_remap = json.loads(data_remap)
except Exception as exc:
  data_remap = None

# The language remapping table dictionary.
#
# This is generated by the langremap utility program.  It is a string
# literal that stores a JSON object.
#
# After the literal data declaration below, the value data_langremap
# will be parsed into a dictionary that maps string keys to string
# values.
#
# If the parsing fails, None will be stored in data_langremap.
# Functions that make use of this embedded table will then raise
# EmbeddedParsingError.
#
# BEGIN AUTO-GENERATED CODE:
data_langremap = r'''{
  "aam": "aas",
  "acc": "acr",
  "adp": "dz",
  "aex": "eng",
  "ahe": "knx",
  "asd": "snz",
  "aue": "ktz",
  "auv": "oci",
  "ayx": "nun",
  "bgh": "bbh",
  "bgm": "bcg",
  "bic": "bir",
  "bjd": "drl",
  "bke": "pse",
  "blg": "iba",
  "bnh": "jaa",
  "boc": "xkl",
  "bqe": "eus",
  "bsd": "bsb",
  "bsz": "eus",
  "bxt": "bgk",
  "cbm": "cak",
  "ccq": "rki",
  "cjr": "mom",
  "cka": "cmr",
  "ckc": "cak",
  "ckd": "cak",
  "cke": "cak",
  "ckf": "cak",
  "cki": "cak",
  "ckj": "cak",
  "ckk": "cak",
  "ckw": "cak",
  "cmk": "xch",
  "cnm": "cac",
  "coy": "pij",
  "cqu": "quh",
  "cru": "bwi",
  "cti": "ctu",
  "cun": "quc",
  "dat": "mhu",
  "dit": "dif",
  "drh": "khk",
  "drr": "kzk",
  "drw": "prs",
  "eni": "pse",
  "fri": "fry",
  "gav": "dev",
  "gen": "mxj",
  "gfx": "vaj",
  "ggn": "gvr",
  "gli": "kzk",
  "gsc": "oci",
  "gti": "nyc",
  "guv": "duz",
  "hrr": "jal",
  "hsf": "hus",
  "hva": "hus",
  "ibi": "opa",
  "ilw": "gal",
  "in": "id",
  "itu": "mzu",
  "iw": "he",
  "ixi": "ixl",
  "ixj": "ixl",
  "jai": "jac",
  "jap": "jaa",
  "jeg": "oyb",
  "ji": "yi",
  "jw": "jv",
  "kgc": "tdf",
  "kgh": "kml",
  "kob": "xsu",
  "koj": "kwv",
  "krg": "khe",
  "krm": "bmf",
  "krq": "ljp",
  "ktr": "dtp",
  "kvs": "gdj",
  "kwq": "yam",
  "kxe": "tvd",
  "kxg": "nij",
  "kxl": "kru",
  "kzj": "dtp",
  "kzt": "dtp",
  "lii": "raq",
  "llo": "ngt",
  "lmm": "rmx",
  "lms": "oci",
  "lmt": "mui",
  "lnc": "oci",
  "lnt": "pse",
  "meg": "cir",
  "miv": "amj",
  "mms": "mam",
  "mo": "ro",
  "mol": "ron",
  "mpf": "mam",
  "mqd": "xkl",
  "mst": "mry",
  "mtz": "mam",
  "mvc": "mam",
  "mvj": "mam",
  "mwj": "vaj",
  "myd": "aog",
  "myt": "mry",
  "nad": "xny",
  "ncp": "kdz",
  "nfg": "nfd",
  "nfk": "nfd",
  "nhj": "nhi",
  "nns": "nbr",
  "nnx": "ngv",
  "nts": "pij",
  "nxj": "byd",
  "nxu": "bpp",
  "occ": "ile",
  "ogn": "pse",
  "ope": "peo",
  "oun": "vaj",
  "paj": "kpc",
  "pat": "kxr",
  "pcr": "adx",
  "pec": "ljp",
  "pen": "mui",
  "plm": "mui",
  "pmc": "huw",
  "pmu": "phr",
  "poa": "poc",
  "pob": "poh",
  "poj": "pkb",
  "pou": "poc",
  "ppa": "bfy",
  "ppr": "lcq",
  "prv": "oci",
  "pry": "prt",
  "pun": "ljp",
  "puz": "pub",
  "quj": "quc",
  "qut": "quc",
  "quu": "quc",
  "qxi": "quc",
  "rae": "ljp",
  "rws": "mui",
  "sca": "hle",
  "scc": "srp",
  "scr": "hrv",
  "sdd": "pse",
  "sdi": "liw",
  "skk": "oyb",
  "skl": "knx",
  "slb": "loe",
  "srj": "pse",
  "suu": "ljp",
  "szk": "ikz",
  "tdu": "dtp",
  "thc": "tpo",
  "thw": "ola",
  "thx": "oyb",
  "tie": "ras",
  "tkk": "twm",
  "tle": "enb",
  "tlw": "weo",
  "tlz": "rob",
  "tmp": "tyj",
  "tmx": "ybi",
  "tne": "kak",
  "tnf": "prs",
  "tnj": "kxn",
  "tsf": "taj",
  "ttx": "bsb",
  "tzb": "tzh",
  "tzc": "tzo",
  "tze": "tzo",
  "tzs": "tzo",
  "tzt": "tzj",
  "tzu": "tzo",
  "tzz": "tzo",
  "uok": "ema",
  "vky": "kge",
  "vmo": "min",
  "xah": "nij",
  "xba": "cax",
  "xia": "acn",
  "xkh": "waw",
  "xrq": "dmw",
  "xsj": "suj",
  "xsk": "kho",
  "xuf": "awn",
  "ybd": "rki",
  "yib": "eng",
  "yio": "lpo",
  "yma": "lrr",
  "ymt": "mtm",
  "yos": "zom",
  "yus": "yua",
  "yuu": "yug",
  "ywm": "ywu",
  "zir": "scv",
  "ztc": "zty"
}'''
# END AUTO-GENERATED CODE.
try:
  data_langremap = json.loads(data_langremap)
except Exception as exc:
  data_langremap = None

# The simplification dictionary.
#
# This is generated by the langsimp utility program.  It is a string
# literal that stores a JSON object.
#
# After the literal data declaration below, the value data_langsimp
# will be parsed into a dictionary that maps string keys to string
# values.
#
# If the parsing fails, None will be stored in data_langsimp.  Functions
# that make use of this embedded table will then raise 
# EmbeddedParsingError.
#
# BEGIN AUTO-GENERATED CODE:
data_langsimp = r'''{
  "aar": "aa",
  "abk": "ab",
  "afr": "af",
  "aka": "ak",
  "alb": "sq",
  "amh": "am",
  "ara": "ar",
  "arg": "an",
  "arm": "hy",
  "asm": "as",
  "ava": "av",
  "ave": "ae",
  "aym": "ay",
  "aze": "az",
  "bak": "ba",
  "bam": "bm",
  "baq": "eu",
  "bel": "be",
  "ben": "bn",
  "bih": "bh",
  "bis": "bi",
  "bod": "bo",
  "bos": "bs",
  "bre": "br",
  "bul": "bg",
  "bur": "my",
  "cat": "ca",
  "ces": "cs",
  "cha": "ch",
  "che": "ce",
  "chi": "zh",
  "chu": "cu",
  "chv": "cv",
  "cor": "kw",
  "cos": "co",
  "cre": "cr",
  "cym": "cy",
  "cze": "cs",
  "dan": "da",
  "deu": "de",
  "div": "dv",
  "dut": "nl",
  "dzo": "dz",
  "ell": "el",
  "eng": "en",
  "epo": "eo",
  "est": "et",
  "eus": "eu",
  "ewe": "ee",
  "fao": "fo",
  "fas": "fa",
  "fij": "fj",
  "fin": "fi",
  "fra": "fr",
  "fre": "fr",
  "fry": "fy",
  "ful": "ff",
  "geo": "ka",
  "ger": "de",
  "gla": "gd",
  "gle": "ga",
  "glg": "gl",
  "glv": "gv",
  "gre": "el",
  "grn": "gn",
  "guj": "gu",
  "hat": "ht",
  "hau": "ha",
  "hbs": "sh",
  "heb": "he",
  "her": "hz",
  "hin": "hi",
  "hmo": "ho",
  "hrv": "hr",
  "hun": "hu",
  "hye": "hy",
  "ibo": "ig",
  "ice": "is",
  "ido": "io",
  "iii": "ii",
  "iku": "iu",
  "ile": "ie",
  "ina": "ia",
  "ind": "id",
  "ipk": "ik",
  "isl": "is",
  "ita": "it",
  "jav": "jv",
  "jpn": "ja",
  "kal": "kl",
  "kan": "kn",
  "kas": "ks",
  "kat": "ka",
  "kau": "kr",
  "kaz": "kk",
  "khm": "km",
  "kik": "ki",
  "kin": "rw",
  "kir": "ky",
  "kom": "kv",
  "kon": "kg",
  "kor": "ko",
  "kua": "kj",
  "kur": "ku",
  "lao": "lo",
  "lat": "la",
  "lav": "lv",
  "lim": "li",
  "lin": "ln",
  "lit": "lt",
  "ltz": "lb",
  "lub": "lu",
  "lug": "lg",
  "mac": "mk",
  "mah": "mh",
  "mal": "ml",
  "mao": "mi",
  "mar": "mr",
  "may": "ms",
  "mkd": "mk",
  "mlg": "mg",
  "mlt": "mt",
  "mon": "mn",
  "mri": "mi",
  "msa": "ms",
  "mya": "my",
  "nau": "na",
  "nav": "nv",
  "nbl": "nr",
  "nde": "nd",
  "ndo": "ng",
  "nep": "ne",
  "nld": "nl",
  "nno": "nn",
  "nob": "nb",
  "nor": "no",
  "nya": "ny",
  "oci": "oc",
  "oji": "oj",
  "ori": "or",
  "orm": "om",
  "oss": "os",
  "pan": "pa",
  "per": "fa",
  "pli": "pi",
  "pol": "pl",
  "por": "pt",
  "pus": "ps",
  "que": "qu",
  "roh": "rm",
  "ron": "ro",
  "rum": "ro",
  "run": "rn",
  "rus": "ru",
  "sag": "sg",
  "san": "sa",
  "sin": "si",
  "slk": "sk",
  "slo": "sk",
  "slv": "sl",
  "sme": "se",
  "smo": "sm",
  "sna": "sn",
  "snd": "sd",
  "som": "so",
  "sot": "st",
  "spa": "es",
  "sqi": "sq",
  "srd": "sc",
  "srp": "sr",
  "ssw": "ss",
  "sun": "su",
  "swa": "sw",
  "swe": "sv",
  "tah": "ty",
  "tam": "ta",
  "tat": "tt",
  "tel": "te",
  "tgk": "tg",
  "tgl": "tl",
  "tha": "th",
  "tib": "bo",
  "tir": "ti",
  "ton": "to",
  "tsn": "tn",
  "tso": "ts",
  "tuk": "tk",
  "tur": "tr",
  "twi": "tw",
  "uig": "ug",
  "ukr": "uk",
  "urd": "ur",
  "uzb": "uz",
  "ven": "ve",
  "vie": "vi",
  "vol": "vo",
  "wel": "cy",
  "wln": "wa",
  "wol": "wo",
  "xho": "xh",
  "yid": "yi",
  "yor": "yo",
  "zha": "za",
  "zho": "zh",
  "zul": "zu"
}'''
# END AUTO-GENERATED CODE.
try:
  data_langsimp = json.loads(data_langsimp)
except Exception as exc:
  data_langsimp = None

# The elaboration dictionary.
#
# This is generated by the elaremap utility program.  It is a string
# literal that stores a JSON object.
#
# After the literal data declaration below, the value data_elaborate
# will be parsed into a dictionary that maps string keys to string
# values.
#
# If the parsing fails, None will be stored in data_elaborate.
# Functions that make use of this embedded table will then raise
# EmbeddedParsingError.
#
# BEGIN AUTO-GENERATED CODE:
data_elaborate = r'''{
  "BU": "MM",
  "DD": "DE",
  "FX": "FR",
  "TP": "TL",
  "YD": "YE",
  "ZR": "CD",
  "heploc": "alalc97"
}'''
# END AUTO-GENERATED CODE.
try:
  data_elaborate = json.loads(data_elaborate)
except Exception as exc:
  data_elaborate = None

# The script suppression dictionary.
#
# This is generated by the dropscript utility program.  It is a string
# literal that stores a JSON object.
#
# After the literal data declaration below, the value data_script will
# be parsed into a dictionary that maps string keys to string values.
#
# If the parsing fails, None will be stored in data_script.  Functions
# that make use of this embedded table will then raise 
# EmbeddedParsingError.
#
# BEGIN AUTO-GENERATED CODE:
data_script = r'''{
  "ab": "Cyrl",
  "af": "Latn",
  "am": "Ethi",
  "ar": "Arab",
  "as": "Beng",
  "ay": "Latn",
  "be": "Cyrl",
  "bg": "Cyrl",
  "bn": "Beng",
  "bs": "Latn",
  "ca": "Latn",
  "ch": "Latn",
  "cs": "Latn",
  "cy": "Latn",
  "da": "Latn",
  "de": "Latn",
  "dv": "Thaa",
  "dz": "Tibt",
  "el": "Grek",
  "en": "Latn",
  "eo": "Latn",
  "es": "Latn",
  "et": "Latn",
  "eu": "Latn",
  "fa": "Arab",
  "fi": "Latn",
  "fj": "Latn",
  "fo": "Latn",
  "fr": "Latn",
  "fy": "Latn",
  "ga": "Latn",
  "gl": "Latn",
  "gn": "Latn",
  "gu": "Gujr",
  "gv": "Latn",
  "he": "Hebr",
  "hi": "Deva",
  "hr": "Latn",
  "ht": "Latn",
  "hu": "Latn",
  "hy": "Armn",
  "id": "Latn",
  "in": "Latn",
  "is": "Latn",
  "it": "Latn",
  "iw": "Hebr",
  "ja": "Jpan",
  "ka": "Geor",
  "kk": "Cyrl",
  "kl": "Latn",
  "km": "Khmr",
  "kn": "Knda",
  "ko": "Kore",
  "la": "Latn",
  "lb": "Latn",
  "ln": "Latn",
  "lo": "Laoo",
  "lt": "Latn",
  "lv": "Latn",
  "mg": "Latn",
  "mh": "Latn",
  "mk": "Cyrl",
  "ml": "Mlym",
  "mo": "Latn",
  "mr": "Deva",
  "ms": "Latn",
  "mt": "Latn",
  "my": "Mymr",
  "na": "Latn",
  "nb": "Latn",
  "nd": "Latn",
  "ne": "Deva",
  "nl": "Latn",
  "nn": "Latn",
  "no": "Latn",
  "nr": "Latn",
  "ny": "Latn",
  "om": "Latn",
  "or": "Orya",
  "pa": "Guru",
  "pl": "Latn",
  "ps": "Arab",
  "pt": "Latn",
  "qu": "Latn",
  "rm": "Latn",
  "rn": "Latn",
  "ro": "Latn",
  "ru": "Cyrl",
  "rw": "Latn",
  "sg": "Latn",
  "si": "Sinh",
  "sk": "Latn",
  "sl": "Latn",
  "sm": "Latn",
  "so": "Latn",
  "sq": "Latn",
  "ss": "Latn",
  "st": "Latn",
  "sv": "Latn",
  "sw": "Latn",
  "ta": "Taml",
  "te": "Telu",
  "th": "Thai",
  "ti": "Ethi",
  "tl": "Latn",
  "tn": "Latn",
  "to": "Latn",
  "tr": "Latn",
  "ts": "Latn",
  "uk": "Cyrl",
  "ur": "Arab",
  "ve": "Latn",
  "vi": "Latn",
  "xh": "Latn",
  "yi": "Hebr",
  "zu": "Latn",
  "dsb": "Latn",
  "frr": "Latn",
  "frs": "Latn",
  "gsw": "Latn",
  "hsb": "Latn",
  "kok": "Deva",
  "mai": "Deva",
  "men": "Latn",
  "nds": "Latn",
  "niu": "Latn",
  "nqo": "Nkoo",
  "nso": "Latn",
  "tem": "Latn",
  "tkl": "Latn",
  "tmh": "Latn",
  "tpi": "Latn",
  "tvl": "Latn",
  "zbl": "Blis"
}'''
# END AUTO-GENERATED CODE.
try:
  data_script = json.loads(data_script)
except Exception as exc:
  data_script = None

# The macrolanguage dictionary.
#
# This is generated by the macrolang utility program.  It is a string
# literal that stores a JSON object.
#
# After the literal data declaration below, the value data_macro will be
# parsed into a dictionary that maps string keys to string values.
#
# If the parsing fails, None will be stored in data_macro.  Functions
# that make use of this embedded table will then raise
# EmbeddedParsingError.
#
# BEGIN AUTO-GENERATED CODE:
data_macro = r'''{
  "aae": "sq",
  "aao": "ar",
  "aat": "sq",
  "abh": "ar",
  "abv": "ar",
  "acm": "ar",
  "acq": "ar",
  "acw": "ar",
  "acx": "ar",
  "acy": "ar",
  "adf": "ar",
  "aeb": "ar",
  "aec": "ar",
  "afb": "ar",
  "aii": "syr",
  "ajp": "ar",
  "ajt": "jrb",
  "aju": "jrb",
  "aln": "sq",
  "als": "sq",
  "apc": "ar",
  "apd": "ar",
  "arb": "ar",
  "arq": "ar",
  "ars": "ar",
  "ary": "ar",
  "arz": "ar",
  "auz": "ar",
  "avl": "ar",
  "ayc": "ay",
  "ayh": "ar",
  "ayl": "ar",
  "ayn": "ar",
  "ayp": "ar",
  "ayr": "ay",
  "azb": "az",
  "azj": "az",
  "bbz": "ar",
  "bcc": "bal",
  "bcl": "bik",
  "bdt": "gba",
  "bgn": "bal",
  "bgp": "bal",
  "bgq": "raj",
  "bhk": "bik",
  "bhr": "mg",
  "bjn": "ms",
  "bjq": "mg",
  "bln": "bik",
  "blu": "hmn",
  "bmm": "mg",
  "bs": "sh",
  "btj": "ms",
  "bto": "bik",
  "bve": "ms",
  "bvu": "ms",
  "bxk": "luy",
  "bxm": "bua",
  "bxr": "bua",
  "bxu": "bua",
  "bzc": "mg",
  "ccx": "za",
  "ccy": "za",
  "cdo": "zh",
  "ciw": "oj",
  "cjy": "zh",
  "ckb": "ku",
  "cld": "syr",
  "cmn": "zh",
  "cnp": "zh",
  "cnr": "sh",
  "coa": "ms",
  "cpx": "zh",
  "cqd": "hmn",
  "crj": "cr",
  "crk": "cr",
  "crl": "cr",
  "crm": "cr",
  "csp": "zh",
  "csw": "cr",
  "cts": "bik",
  "cwd": "cr",
  "czh": "zh",
  "czo": "zh",
  "dgo": "doi",
  "dhd": "mwr",
  "dib": "din",
  "dik": "din",
  "dip": "din",
  "diq": "zza",
  "diw": "din",
  "dks": "din",
  "dty": "ne",
  "dup": "ms",
  "ebk": "bnc",
  "ekk": "et",
  "emk": "man",
  "enb": "kln",
  "esg": "gon",
  "esi": "ik",
  "esk": "ik",
  "eyo": "kln",
  "fat": "ak",
  "fbl": "bik",
  "ffm": "ff",
  "fub": "ff",
  "fuc": "ff",
  "fue": "ff",
  "fuf": "ff",
  "fuh": "ff",
  "fui": "ff",
  "fuq": "ff",
  "fuv": "ff",
  "gan": "zh",
  "gax": "om",
  "gaz": "om",
  "gbo": "grb",
  "gbp": "gba",
  "gbq": "gba",
  "gda": "raj",
  "gec": "grb",
  "ggo": "gon",
  "gju": "raj",
  "gkp": "kpe",
  "gmm": "gba",
  "gno": "gon",
  "gnw": "gn",
  "gom": "kok",
  "grj": "grb",
  "grv": "grb",
  "gry": "grb",
  "gso": "gba",
  "gug": "gn",
  "gui": "gn",
  "gun": "gn",
  "gya": "gba",
  "hae": "om",
  "hak": "zh",
  "hax": "hai",
  "hdn": "hai",
  "hea": "hmn",
  "hji": "ms",
  "hma": "hmn",
  "hmc": "hmn",
  "hmd": "hmn",
  "hme": "hmn",
  "hmg": "hmn",
  "hmh": "hmn",
  "hmi": "hmn",
  "hmj": "hmn",
  "hml": "hmn",
  "hmm": "hmn",
  "hmp": "hmn",
  "hmq": "hmn",
  "hms": "hmn",
  "hmw": "hmn",
  "hmy": "hmn",
  "hmz": "hmn",
  "hnd": "lah",
  "hnj": "hmn",
  "hno": "lah",
  "hoj": "raj",
  "hr": "sh",
  "hrm": "hmn",
  "hsn": "zh",
  "huj": "hmn",
  "id": "ms",
  "ida": "luy",
  "ike": "iu",
  "ikt": "iu",
  "jak": "ms",
  "jat": "lah",
  "jax": "ms",
  "jye": "jrb",
  "kby": "kr",
  "khk": "mn",
  "kiu": "zza",
  "kmr": "ku",
  "knc": "kr",
  "kng": "kg",
  "knn": "kok",
  "koi": "kv",
  "kpv": "kv",
  "krt": "kr",
  "kvb": "ms",
  "kvr": "ms",
  "kwy": "kg",
  "kxd": "ms",
  "lbk": "bnc",
  "lbl": "bik",
  "lce": "ms",
  "lcf": "ms",
  "ldi": "kg",
  "liw": "ms",
  "lkb": "luy",
  "lko": "luy",
  "lks": "luy",
  "lri": "luy",
  "lrm": "luy",
  "lsm": "luy",
  "ltg": "lv",
  "lto": "luy",
  "lts": "luy",
  "lvs": "lv",
  "lwg": "luy",
  "lzh": "zh",
  "max": "ms",
  "mdo": "gba",
  "meo": "ms",
  "mfa": "ms",
  "mfb": "ms",
  "mhr": "chm",
  "min": "ms",
  "mku": "man",
  "mlq": "man",
  "mly": "ms",
  "mmr": "hmn",
  "mnk": "man",
  "mnp": "zh",
  "mqg": "ms",
  "mrj": "chm",
  "msc": "man",
  "msh": "mg",
  "msi": "ms",
  "mtr": "mwr",
  "mui": "ms",
  "mup": "raj",
  "muq": "hmn",
  "mve": "mwr",
  "mvf": "mn",
  "mwk": "man",
  "mww": "hmn",
  "myq": "man",
  "nan": "zh",
  "nb": "no",
  "nhd": "gn",
  "niq": "kln",
  "nle": "luy",
  "nn": "no",
  "npi": "ne",
  "nyd": "luy",
  "obk": "bnc",
  "ojb": "oj",
  "ojc": "oj",
  "ojg": "oj",
  "ojs": "oj",
  "ojw": "oj",
  "oki": "kln",
  "orc": "om",
  "orn": "ms",
  "ors": "ms",
  "ory": "or",
  "otw": "oj",
  "pbt": "ps",
  "pbu": "ps",
  "pel": "ms",
  "pes": "fa",
  "pga": "ar",
  "phr": "lah",
  "pko": "kln",
  "plt": "mg",
  "pnb": "lah",
  "prs": "fa",
  "pse": "ms",
  "pst": "ps",
  "qub": "qu",
  "qud": "qu",
  "quf": "qu",
  "qug": "qu",
  "quh": "qu",
  "quk": "qu",
  "qul": "qu",
  "qup": "qu",
  "qur": "qu",
  "qus": "qu",
  "quw": "qu",
  "qux": "qu",
  "quy": "qu",
  "quz": "qu",
  "qva": "qu",
  "qvc": "qu",
  "qve": "qu",
  "qvh": "qu",
  "qvi": "qu",
  "qvj": "qu",
  "qvl": "qu",
  "qvm": "qu",
  "qvn": "qu",
  "qvo": "qu",
  "qvp": "qu",
  "qvs": "qu",
  "qvw": "qu",
  "qvz": "qu",
  "qwa": "qu",
  "qwc": "qu",
  "qwh": "qu",
  "qws": "qu",
  "qxa": "qu",
  "qxc": "qu",
  "qxh": "qu",
  "qxl": "qu",
  "qxn": "qu",
  "qxo": "qu",
  "qxp": "qu",
  "qxr": "qu",
  "qxt": "qu",
  "qxu": "qu",
  "qxw": "qu",
  "rag": "luy",
  "rbk": "bnc",
  "rbl": "bik",
  "rmc": "rom",
  "rmf": "rom",
  "rml": "rom",
  "rmn": "rom",
  "rmo": "rom",
  "rmw": "rom",
  "rmy": "rom",
  "rwr": "mwr",
  "scs": "den",
  "sdc": "sc",
  "sdh": "ku",
  "sdn": "sc",
  "sfm": "hmn",
  "sgc": "kln",
  "shu": "ar",
  "skg": "mg",
  "skr": "lah",
  "spv": "or",
  "spy": "kln",
  "sr": "sh",
  "src": "sc",
  "sro": "sc",
  "ssh": "ar",
  "swc": "sw",
  "swh": "sw",
  "swv": "mwr",
  "taq": "tmh",
  "tdx": "mg",
  "tec": "kln",
  "thv": "tmh",
  "thz": "tmh",
  "tkg": "mg",
  "tmw": "ms",
  "ttq": "tmh",
  "tuy": "kln",
  "tw": "ak",
  "txy": "mg",
  "ubl": "bik",
  "umu": "del",
  "unm": "del",
  "urk": "ms",
  "uzn": "uz",
  "uzs": "uz",
  "vbk": "bnc",
  "vkk": "ms",
  "vkt": "ms",
  "vro": "et",
  "wbr": "raj",
  "wry": "mwr",
  "wsg": "gon",
  "wuu": "zh",
  "xhe": "lah",
  "xmm": "ms",
  "xmv": "mg",
  "xmw": "mg",
  "xnr": "doi",
  "xpe": "kpe",
  "xsl": "den",
  "ydd": "yi",
  "yhd": "jrb",
  "yih": "yi",
  "yud": "jrb",
  "yue": "zh",
  "zaa": "zap",
  "zab": "zap",
  "zac": "zap",
  "zad": "zap",
  "zae": "zap",
  "zaf": "zap",
  "zai": "zap",
  "zam": "zap",
  "zao": "zap",
  "zaq": "zap",
  "zar": "zap",
  "zas": "zap",
  "zat": "zap",
  "zav": "zap",
  "zaw": "zap",
  "zax": "zap",
  "zca": "zap",
  "zch": "za",
  "zeh": "za",
  "zgb": "za",
  "zgm": "za",
  "zgn": "za",
  "zhd": "za",
  "zhn": "za",
  "zlj": "za",
  "zlm": "ms",
  "zln": "za",
  "zlq": "za",
  "zmi": "ms",
  "zoo": "zap",
  "zpa": "zap",
  "zpb": "zap",
  "zpc": "zap",
  "zpd": "zap",
  "zpe": "zap",
  "zpf": "zap",
  "zpg": "zap",
  "zph": "zap",
  "zpi": "zap",
  "zpj": "zap",
  "zpk": "zap",
  "zpl": "zap",
  "zpm": "zap",
  "zpn": "zap",
  "zpo": "zap",
  "zpp": "zap",
  "zpq": "zap",
  "zpr": "zap",
  "zps": "zap",
  "zpt": "zap",
  "zpu": "zap",
  "zpv": "zap",
  "zpw": "zap",
  "zpx": "zap",
  "zpy": "zap",
  "zpz": "zap",
  "zqe": "za",
  "zsm": "ms",
  "zsr": "zap",
  "zte": "zap",
  "ztg": "zap",
  "ztl": "zap",
  "ztm": "zap",
  "ztn": "zap",
  "ztp": "zap",
  "ztq": "zap",
  "zts": "zap",
  "ztt": "zap",
  "ztu": "zap",
  "ztx": "zap",
  "zty": "zap",
  "zyb": "za",
  "zyg": "za",
  "zyj": "za",
  "zyn": "za",
  "zzj": "za"
}'''
# END AUTO-GENERATED CODE.
try:
  data_macro = json.loads(data_macro)
except Exception as exc:
  data_macro = None

#
# Local functions
# ---------------
#

# Append a tag separator to the given string if it is not empty, else
# return the tag as-is.
#
# Parameters:
#
#   s : string - the string value
#
# Return:
#
#   the string value as-is if it is empty, otherwise the string value
#   with a hyphen appended
#
def tagsep(s):
  if not isinstance(s, str):
    raise LogicError()
  
  if len(s) > 0:
    return s + '-'
  else:
    return s

# Check whether a given string matches a given format.
#
# s is the string value to check for a match.
#
# fstr is the format string.  It must be a string, and it may be empty.
# The length of s must match the length of fstr for there to be a match.
# Also, each charset in the format string must contain the corresponding
# character in the given string to match.
#
# The charset codes are as follows (case sensitive):
#
#   a - match a lowercase ASCII letter
#   A - match an uppercase ASCII letter
#   D - match an ASCII digit
#
# Parameters:
#
#   s : str - the string to check the format of
#
#   fstr : str - the format string specifying the format to check for
#
# Return:
#
#   True if there is a match, False if there is not
#
def matchformat(s, fstr):
  
  # Check parameters
  if not isinstance(s, str) or not isinstance(fstr, str):
    raise LogicError()
  
  for c in fstr:
    if (c != 'a') and (c != 'A') and (c != 'D'):
      raise LogicError()
  
  # If length of given string doesn't match length of format string, no
  # match
  if len(s) != len(fstr):
    return False
  
  # Check that each character is appropriate
  for x in range(0, len(fstr)):
    
    # Get current character code and charset
    c = ord(s[x])
    cs = fstr[x]
    
    # Check that character code is in charset
    if cs == 'a':
      if (c < ord('a')) or (c > ord('z')):
        return False
      
    elif cs == 'A':
      if (c < ord('A')) or (c > ord('Z')):
        return False
      
    elif cs == 'D':
      if (c < ord('0')) or (c > ord('9')):
        return False
      
    else:
      raise LogicError()
  
  # If we got all the way here, there is a match
  return True

#
# Class definitions
# -----------------
#

# Instances of the LangParse class store parsed language tags.
#
# Use one of the public parsing functions defined later in this module
# to get instances of this class, rather than constructing it directly.
#
# When first constructed, all fields are set to None indicating that
# there is nothing stored in the instance.  However, a special
# constructor parameter is able to copy extension codes and private
# subtags in from another LangParse instance.
#
# After construction, object instances are mutable.  You can use the
# addSubtag() method to add different kinds of subtags, addExtension()
# to add extension codes, and addPrivate() to add private tags.
#
# Once everything is set, you call complete() to check that the state of
# the object is valid and then freeze the object so it becomes
# immutable.  The parsing functions defined later in this module always
# return instances of this class in this completed, immutable state.
# You can use isComplete() to check whether an instance has been
# completed.
#
# The following read-only properties are always available:
#
#   Property |  Allowed types
#   ---------|-----------------
#   .plang   | str       | None
#   .extlang | str       | None
#   .ilang   | str       | None
#   .script  | str       | None
#   .region  | str       | None
#   .variant | list(str) | None
#
# The .variant property always returns new copies of the list so that
# the internal list is unmodifiable.  Each property can return None if
# it wasn't set.  If there are no variant tags, the property will always
# return None rather than an empty list.
#
# Extension codes and private-use tags can't be directly accessed by
# properties, though they are properly stored within the object.
#
# You can use the assemble() function on any object that has been
# completed with complete().  This function assembles a full language
# tag from all the components stored within the object (including the
# extension codes and the private tags), with everything in the proper
# order.
#
class LangParse:
  
  # Constructor.
  #
  # Optionally, pass an object instance to copy the extension codes and
  # private-use tags from.
  #
  # Parameters:
  #
  #   src : LangParse | None - the source object to copy extension codes
  #   and private-use tags from, or None to start out with no extension
  #   codes and no private-use tags
  #
  def __init__(self, src=None):
    
    # Check parameter
    if src is not None:
      if not isinstance(src, LangParse):
        raise LogicError()
    
    # Start out in incomplete state
    self.m_complete = False
    
    # Initialize all fields
    self.m_plang = None
    self.m_extlang = None
    self.m_ilang = None
    self.m_script = None
    self.m_region = None
    self.m_variant = None
    self.m_extcode = None
    self.m_private = None
    
    # If we have a source parameter, copy in the extension and private
    # fields
    if src is not None:
      self.m_extcode = src.m_extcode
      self.m_private = src.m_private

  # Check that the field configuration is acceptable and freeze the
  # object to make it immutable.
  #
  # If the object instance has already been frozen, calling this
  # function again has no effect.
  #
  # LogicError is thrown if the field configuration is unacceptable.
  #
  def complete(self):

    # Ignore call if already completed
    if self.m_complete:
      return
    
    # At least one field must have been set
    if (self.m_plang is None) and (self.m_extlang is None) and \
        (self.m_ilang is None) and (self.m_script is None) and \
        (self.m_region is None) and (self.m_variant is None) and \
        (self.m_extcode is None) and (self.m_private is None):
      raise LogicError()
    
    # If the irregular language field is set, all other fields must be
    # empty
    if self.m_ilang is not None:
      if (self.m_plang is not None) or (self.m_extlang is not None) or \
          (self.m_script is not None) or \
          (self.m_region is not None) or \
          (self.m_variant is not None) or \
          (self.m_extcode is not None) or \
          (self.m_private is not None):
        raise LogicError()

    # If the primary language field is not set, then no other field
    # except for irregular language or private subtags can be set
    if self.m_plang is None:
      if (self.m_extlang is not None) or \
          (self.m_script is not None) or \
          (self.m_region is not None) or \
          (self.m_variant is not None) or \
          (self.m_extcode is not None):
        raise LogicError()
    
    # If we got here, the field configuration is valid, so complete the
    # object instance
    self.m_complete = True
  
  # Check whether this object instance is complete.
  #
  # Return:
  #
  #   True if this object instance is completed, False if not
  #
  def isComplete(self):
    return self.m_complete
  
  # Add a subtag to the object instance.
  #
  # This can only be used on objects that haven't been completed yet.
  # LogicError is thrown if this is called on an object that has had its
  # complete() function already used.
  #
  # st is the type of subtag to add while val is the value of the
  # subtag.  You can only add the following types of subtags using this
  # function:
  #
  #    st value |          Meaning
  #   ----------|---------------------------
  #   'plang'   | Primary language subtag
  #   'extlang' | Secondary language subtag
  #   'ilang'   | Irregular language subtag
  #   'script'  | Script subtag
  #   'region'  | Region subtag
  #   'variant' | Variant subtag
  #
  # To add extension codes, use the addExtension() method.  To add
  # private-use subtags, use the addPrivate() method.
  #
  # The given value must always follow these formatting guidelines or a
  # LogicError is thrown:
  #
  #   (1) Value must be a string
  #   (2) Value must be at least one character
  #   (3) All characters must be ASCII alphanumeric or hyphen
  #
  # In addition, the following subtag types only allow lowercase
  # letters, with a LogicError thrown if uppercase letters are
  # encountered:
  #
  #   plang, extlang, ilang, variant
  #
  # The following subtag type only allows uppercase letters, with a
  # LogicError thrown if lowercase letters are encountered:
  #
  #   region
  #
  # The following subtag type requires the first character to be an
  # uppercase letter and all subsequent characters to be lowercase
  # letters or a LogicError is thrown:
  #
  #   script
  #
  # The following additional formatting rules are also enforced:
  #
  #   (A) plang must be only letters
  #   (B) extlang must be exactly three letters
  #   (C) script must be exactly four letters
  #   (D) region must be two letters or three digits
  #
  # If all the format checks pass, then the last check that is performed
  # is to see whether the subtag has already been set.  The function
  # fails and False is returned if a subtag of the given type has
  # already been set for this object, except for variants, which allow
  # for any number of variant subtags.
  #
  # Parameters:
  #
  #  st : string - the subtag type to set
  #
  #  val : string - the subtag value to set
  #
  # Return:
  #
  #   True if successful, False if subtag type has already been set and
  #   no further subtags allowed of that type
  #
  def addSubtag(self, st, val):
    
    # Check that object not completed yet
    if self.m_complete:
      raise LogicError()
    
    # Check type parameter
    if (st != 'plang') and (st != 'extlang') and \
        (st != 'ilang') and (st != 'script') and \
        (st != 'region') and (st != 'variant'):
      raise LogicError()
    
    # Basic check of value
    if not isinstance(val, str):
      raise LogicError()
    
    if len(val) < 1:
      raise LogicError()
    
    for cc in val:
      c = ord(cc)
      if ((c < ord('a')) or (c > ord('z'))) and \
          ((c < ord('A')) or (c > ord('Z'))) and \
          ((c < ord('0')) or (c > ord('9'))) and \
          (c != ord('-')):
        raise LogicError()
    
    # For all but region and script, make sure no uppercase letters are
    # used
    if (st != 'region') and (st != 'script'):
      for cc in val:
        c = ord(cc)
        if (c >= ord('A')) and (c <= ord('Z')):
          raise LogicError()
    
    # Region must either be two uppercase letters or three digits
    if (st == 'region'):
      if (not matchformat(val, 'AA')) and (not matchformat(val, 'DDD')):
        raise LogicError()
    
    # Script must be four letters, the first uppercase and the rest
    # lowercase
    if (st == 'script'):
      if not matchformat(val, 'Aaaa'):
        raise LogicError()

    # Primary and secondary languages must only have letters
    if (st == 'plang') or (st == 'extlang'):
      if not val.isalpha():
        raise LogicError()
    
    # Secondary language must be exactly three letters
    if (st == 'extlang'):
      if len(val) != 3:
        raise LogicError()
    
    # Format checks passed -- for all but variant, make sure tag type
    # hasn't been set yet or return False
    if st == 'plang':
      if self.m_plang is not None:
        return False
    
    elif st == 'extlang':
      if self.m_extlang is not None:
        return False
      
    elif st == 'ilang':
      if self.m_ilang is not None:
        return False
      
    elif st == 'script':
      if self.m_script is not None:
        return False
      
    elif st == 'region':
      if self.m_region is not None:
        return False
    
    # If we got here, add the subtag
    if st == 'plang':
      self.m_plang = val
    
    elif st == 'extlang':
      self.m_extlang = val
      
    elif st == 'ilang':
      self.m_ilang = val
      
    elif st == 'script':
      self.m_script = val
      
    elif st == 'region':
      self.m_region = val
      
    elif st == 'variant':
      if self.m_variant is None:
        self.m_variant = [val]
      else:
        self.m_variant.append(val)
      
    else:
      raise LogicError()
      
    # If we got here, return True indicating success
    return True

  # Add an extension code to the object instance.
  #
  # This can only be used on objects that haven't been completed yet.
  # LogicError is thrown if this is called on an object that has had its
  # complete() function already used.
  #
  # extc is the extension code.  It must be a single digit or a single
  # lowercase letter except for the letter x, or else LogicError is
  # thrown.
  #
  # extv is the list of tags to associate with the extension code.  It
  # must be a list of str.  Empty lists are acceptable.  Do NOT include
  # the extension code itself at the beginning of the list.
  #
  # Each str in the extv list must have at least two characters and
  # contain only lowercase letters and digits, or else a LogicError is
  # thrown.
  #
  # If the given extension code has already been added to the object
  # instance or it was inherited from a source object during the
  # constructor, this function fails and returns False.
  #
  # Otherwise, the extension is added to the object.  A copy of the
  # given list is made so that modifications to the list do not affect
  # this object's state.
  #
  # Parameters:
  #
  #   extc : str - the extension code
  #
  #   extv : list of str - the extension tags
  #
  # Return:
  #
  #   True if successful, False if the extension code is already
  #   registered
  #
  def addExtension(self, extc, extv):
    
    # Check that object not completed yet
    if self.m_complete:
      raise LogicError()
    
    # Check extension code parameter
    if not isinstance(extc, str):
      raise LogicError()
    
    if len(extc) != 1:
      raise LogicError()
    
    if (extc == 'x'):
      raise LogicError()
    
    oextc = ord(extc)
    if ((oextc < ord('a')) or (oextc > ord('z'))) and \
        ((oextc < ord('0')) or (oextc > ord('9'))):
      raise LogicError()
    
    # Check extension tag parameter
    if not isinstance(extv, list):
      raise LogicError()
    
    for s in extv:
      if not isinstance(s, str):
        raise LogicError()
      
      if len(s) < 2:
        raise LogicError()
      
      for cc in s:
        c = ord(cc)
        if ((c < ord('a')) or (c > ord('z'))) and \
              ((c < ord('0')) or (c > ord('9'))):
          raise LogicError()

    # If extcode dictionary not yet created, create it
    if self.m_extcode is None:
      self.m_extcode = dict()

    # If extension code is already added, fail and return False
    if extc in self.m_extcode:
      return False
    
    # If we got here, then add the extension code and return True
    self.m_extcode[extc] = extv.copy()
    return True

  # Add private subtags to the object instance.
  #
  # This can only be used on objects that haven't been completed yet.
  # LogicError is thrown if this is called on an object that has had its
  # complete() function already used.
  #
  # ptags is a list of str that stores the private subtags to add to the
  # object.  A copy is made of this list so that subsequent changes to
  # the list do not affect object state.  The list must have at least
  # one element, each element must be a non-empty string, and each
  # element may only contain ASCII lowercase letters and digits.
  #
  # Do NOT include the opening x- marker subtag in the private subtags
  # list.
  #
  # If private subtags have already been added to this object, the
  # function fails and returns False.
  #
  # Parameters:
  #
  #   ptags : list of str - the private subtags to add
  #
  # Return:
  #
  #   True if successful, False if private subtags were already present
  #
  def addPrivate(self, ptags):
    
    # Check that object not completed yet
    if self.m_complete:
      raise LogicError()
    
    # Check private tags parameter
    if not isinstance(ptags, list):
      raise LogicError()
    
    if len(ptags) < 1:
      raise LogicError()
    
    for sv in ptags:
      if not isinstance(sv, str):
        raise LogicError()
      
      if len(sv) < 1:
        raise LogicError()
      
      for cc in sv:
        c = ord(cc)
        if ((c < ord('a')) or (c > ord('z'))) and \
            ((c < ord('0')) or (c > ord('9'))):
          raise LogicError()
    
    # Fail if private subtags already added
    if self.m_private is not None:
      raise LogicError()
    
    # If we got here, store a copy of the private subtags and return
    # True
    self.m_private = ptags.copy()
    return True

  # Dummy function implementation of property set routines that just
  # raises an exception.
  #
  def _block_set(self, value):
    raise LogicError()
  
  # Dummy function implementation of property del routines that just
  # raises an exception.
  #
  def _block_del(self):
    raise LogicError()
  
  # Get routines for each of the properties.
  #
  # Just returns the internal value, except variant property returns a
  # copy of the list.
  #
  def _get_plang(self):
    return self.m_plang
  def _get_extlang(self):
    return self.m_extlang
  def _get_ilang(self):
    return self.m_ilang
  def _get_script(self):
    return self.m_script
  def _get_region(self):
    return self.m_region
  def _get_variant(self):
    if self.m_variant is not None:
      return self.m_variant.copy()
    else:
      return None

  # Read-only property definitions
  #
  plang = property(_get_plang, _block_set, _block_del)
  extlang = property(_get_extlang, _block_set, _block_del)
  ilang = property(_get_ilang, _block_set, _block_del)
  script = property(_get_script, _block_set, _block_del)
  region = property(_get_region, _block_set, _block_del)
  variant = property(_get_variant, _block_set, _block_del)
  
  # Assemble all the data within the object instance into a language tag
  # with all the subtags in the proper order.
  #
  # The object must be completed or a LogicError is thrown.
  #
  # Return:
  #
  #   the assembled language tag as a string
  #
  def assemble(self):
    
    # Check state
    if not self.m_complete:
      raise LogicError()
    
    # Start with an empty string
    result = ''
    
    # Assemble any of the opening subtags in order
    if self.m_plang is not None:
      result = tagsep(result) + self.m_plang
    
    if self.m_extlang is not None:
      result = tagsep(result) + self.m_extlang
    
    if self.m_ilang is not None:
      result = tagsep(result) + self.m_ilang
    
    if self.m_script is not None:
      result = tagsep(result) + self.m_script
    
    if self.m_region is not None:
      result = tagsep(result) + self.m_region
    
    # Assemble any variant subtags
    if self.m_variant is not None:
      for vt in self.m_variant:
        result = tagsep(result) + vt
    
    # Assemble any extensions in proper order
    if self.m_extcode is not None:
      
      # Get a list of all extension codes
      exl = list(self.m_extcode)
      
      # Sort the extension codes
      exl.sort()
      
      # Add all the extensions
      for xk in exl:
        
        # Begin with the extension code singleton
        result = tagsep(result) + xk
        
        # Get the list of extension subtags and add them
        xv = self.m_extcode[xk]
        for sv in xv:
          result = tagsep(result) + sv
      
    # Assemble any private subtags
    if self.m_private is not None:
      
      # Add the private subtag marker
      result = tagsep(result) + 'x'
      
      # Add the private subtags
      for sv in self.m_private:
        result = tagsep(result) + sv
    
    # Return the result
    return result
    
#
# Public functions
# ----------------
#

# Apply universal tag normalization to the given language tag.
#
# This is not a complete tag normalization procedure.  This is only the
# first step in normalizing a language tag.  See the Langtag
# specification for further information.
#
# If the given parameter is not a string or there is a problem applying
# universal tag normalization, None is returned.
#
# Parameters:
#
#   s - str | mixed : the value to apply universal tag normalization to
#
# Return:
#
#   the language tag with universal tag normalization applied, or None
#   if the procedure failed
#
def utnorm(s):

  # Check that a string was provided
  if not isinstance(s, str):
    return None
  
  # Trim leading and trailing whitespace
  s = s.strip()
  
  # Language tag should be non-empty after trimming
  if len(s) < 1:
    return None
  
  # Replace underscores with hyphens
  s = s.replace('_', '-')
  
  # Check that the tag contains only ASCII alphanumerics and hyphens,
  # that neither the first nor last character is a hyphen, and that no
  # hyphen is immediately preceded by another hyphen
  slen = len(s)
  for i in range(0, slen):
    
    # Get current character code
    c = ord(s[i])
    
    # Check kind of character
    if (c >= ord('a')) and (c <= ord('z')):
      # Lowercase alphabetic, so OK
      pass
      
    elif (c >= ord('A')) and (c <= ord('Z')):
      # Uppercase alphabetic, so OK
      pass
      
    elif (c >= ord('0')) and (c <= ord('9')):
      # Numeric digit, so OK
      pass
      
    elif (c == ord('-')):
      # Hyphen, so check that neither the first nor last character
      if (i < 1) or (i >= slen - 1):
        return None
      
      # Also, check that previous character is not a hyphen
      if s[i - 1] == '-':
        return None
      
    else:
      # Invalid language tag character
      return None

  # Convert all letters to lowercase
  s = s.lower()

  # Split into subtags
  sa = s.split('-')
  
  # If there are at least two subtags, apply casing normalization to all
  # subtags after the first one
  if len(sa) > 1:
    for x in range(1, len(sa)):
      
      # Get this subtag and its length
      sv = sa[x]
      svl = len(sv)
      
      # If this subtag has less than two characters, then no more casing
      # transforms are required in the subtag array
      if svl < 2:
        break
      
      # If this subtag is not all letters, skip processing for this
      # subtag
      if not sv.isalpha():
        continue
      
      # Perform casing for special subtag types
      if svl == 2:
        # Two-letter subtags that are not the first subtag and not
        # preceded by a subtag with only one character should be made
        # uppercase
        sa[x] = sv.upper()
        
      elif svl == 4:
        # Four-letter subtags that are not the first subtag and not
        # preceded by a subtag with only one character should be made
        # titlecase
        sa[x] = sv.capitalize()

  # Rejoin all the subtags into a single string value with hyphens used
  # as separators
  s = '-'.join(sa)
  
  # Return the normalized string
  return s

# Apply universal tag normalization and tag remapping to the given
# language tag.
#
# This is a wrapper around utnorm() that first calls that function and
# then if successful it uses the embedded data_remap table to remap
# legacy tags.  EmbeddedParsingError is thrown if there was an error
# parsing the data remap table.
#
# Parameters:
#
#   s - str | mixed : the value to transform
#
# Return:
#
#   the language tag with universal tag normalization and tag remapping
#   applied, or None if the procedure failed
#
def rtnorm(s):
  
  # Check that we have the remap table
  if data_remap is None:
    raise EmbeddedParsingError()
  
  # Perform universal tag normalization
  s = utnorm(s)
  
  # If universal tag normalization failed, return None
  if s is None:
    return None
  
  # If there is a tag remapping, perform it
  if s in data_remap:
    s = data_remap[s]
  
  # Return result
  return s

# Apply universal tag normalization and tag remapping, and then parse
# the given language tag.
#
# This is a wrapper around rtnorm() that first calls that function and
# then if successful it parses fields and returns a completed LangParse
# object instance representing the parsed tag.  None is returned if
# rtnorm() failed or parsing failed.
#
# EmbeddedParsingError may be thrown if the embedded data table used by
# rtnorm() couldn't be loaded correctly.
#
# Parameters:
#
#   s - str | mixed : the value to parse
#
# Return:
#
#   a completed LangParse instance, or None if the procedure failed
#
def parse(s):
  
  # Perform universal tag normalization and tag remapping
  s = rtnorm(s)
  
  # If the process failed, return None
  if s is None:
    return None
  
  # Create an empty parsing object that will be filled in
  po = LangParse()
  
  # If the whole tag is a GG2 or GG3 grandfathered tag (that is, a
  # grandfathered tag in the subtag registry that does not have a
  # Preferred-Value field), then store the whole tag in the irregular
  # language subtag and return the result without any further processing
  if (s == 'cel-gaulish') or (s == 'zh-min') or \
      (s == 'i-default') or (s == 'i-enochian') or (s == 'i-mingo'):
    if not po.addSubtag('ilang', s):
      raise LogicError()
    po.complete()
    return po
  
  # Parse the tag into subtags
  stl = s.split('-')
  
  # Handle the special case of the first subtag being the private marker
  # x-
  if stl[0] == 'x':
    # There must be at least one more subtag or else parsing fails
    if len(stl) < 2:
      return None
    
    # Add all remaining subtags as private tags
    if not po.addPrivate(stl[1:]):
      raise LogicError()
    
    # Complete the parsed object and return it
    po.complete()
    return po
  
  # If we got here, then the first subtag is the primary language
  if not po.addSubtag('plang', stl[0]):
    raise LogicError()
  
  # If there is only one subtag, we are done so complete the parsed
  # object and return it
  if len(stl) < 2:
    po.complete()
    return po
  
  # Additional subtags to process, so drop the primary language subtag
  # before proceeding
  stl = stl[1:]
  
  # Look for the private subtag marker
  if 'x' in stl:
    # Get the index of the private subtag marker
    pmi = stl.index('x')
    
    # If there is at least one subtag after the private subtag marker,
    # add the private subtags to the parsed object
    if pmi < len(stl) - 1:
      if not po.addPrivate(stl[pmi + 1:]):
        raise LogicError()
    
    # Drop the private subtag marker and everything after it
    if pmi > 0:
      stl = stl[0:pmi]
    else:
      stl = []
  
  # Go through remaining subtags and register any extensions in the
  # parsed object
  first_ext = None
  for i in range(0, len(stl)):
    
    # Get current element
    k = stl[i]
    
    # If current element is not exactly one character, skip it
    if len(k) != 1:
      continue
    
    # We found a singleton marking the start of an extension -- if this
    # is the first extension found, save its index for later
    if first_ext is None:
      first_ext = i
    
    # Accumulate all subtags in the extension
    xsl = []
    for j in range(i + 1, len(stl)):
      # Get current element
      v = stl[j]
      
      # If current element is another singleton, we've found the end of
      # the extension, so leave loop; otherwise, add the current element
      # to the extension
      if len(v) == 1:
        break
      else:
        xsl.append(v)
    
    # Register the extension, failing and returning None if the
    # extension code is already registered
    if not po.addExtension(k, xsl):
      return None
  
  # If any extensions were found, drop them from the language tag
  if first_ext is not None:
    if first_ext > 0:
      stl = stl[0:first_ext]
    else:
      stl = []
  
  # Add any remaining subtags
  for sv in stl:
    
    # Determine subtag type by format
    if matchformat(sv, 'aaa'):
      # Secondary language
      if not po.addSubtag('extlang', sv):
        return None
      
    elif matchformat(sv, 'Aaaa'):
      # Script
      if not po.addSubtag('script', sv):
        return None
      
    elif matchformat(sv, 'AA'):
      # Region (country)
      if not po.addSubtag('region', sv):
        return None
      
    elif matchformat(sv, 'DDD'):
      # Region (code)
      if not po.addSubtag('region', sv):
        return None
      
    else:
      # Everything is is variant tag
      if not po.addSubtag('variant', sv):
        raise LogicError()
  
  # If we got here, complete the parsed object and return it
  po.complete()
  return po

# Perform the full language tag normalization process on the given
# language tag.
#
# EmbeddedParsingError is thrown if there was an error parsing any of
# the embedded data tables.
#
# Otherwise, None is returned if the normalization process fails.
#
# This function does *not* guarantee that the returned value is valid.
# You must validate normalized values separately using valid().
#
# Parameters:
#
#   s - str | mixed : the value to transform
#
# Return:
#
#   the normalized language tag, or None if the procedure failed
#
def norm(s):
  
  # Perform universal tag normalization, tag remapping, and tag parsing
  po = parse(s)
  
  # If parsing failed, return None
  if po is None:
    return None
  
  # Check for embedded data tables
  if data_langremap is None:
    raise EmbeddedParsingError()
  if data_langsimp is None:
    raise EmbeddedParsingError()
  if data_elaborate is None:
    raise EmbeddedParsingError()
  if data_script is None:
    raise EmbeddedParsingError()
  
  # Create a new instance to hold the normalized version, copying over
  # the extension codes and private subtags from the parsed object
  pn = LangParse(po)
  
  # Determine the normalized language
  nl = None
  if po.ilang is not None:
    # Irregular language tag, so just copy that over
    if not pn.addSubtag('ilang', po.ilang):
      raise LogicError()
  
  elif po.extlang is not None:
    # Secondary language that should be promoted to main language
    # through extlang promotion
    nl = po.extlang
  
  else:
    # In all other cases, use the primary language, if it is defined
    nl = po.plang
  
  if nl is not None:
    # We got a regular language tag (either the primary or the secondary
    # language from the parsed object), so next we need to apply the
    # language remapping dictionary
    if nl in data_langremap:
      nl = data_langremap[nl]
    
    # Next, apply simplification mapping if necessary
    if nl in data_langsimp:
      nl = data_langsimp[nl]
    
    # We can now store the normalized language
    if not pn.addSubtag('plang', nl):
      raise LogicError()
  
  # If script is present, determine normalized form
  if po.script is not None:
    # Get the current script setting
    s = po.script
    
    # If script is in elaboration dictionary, remap it
    if s in data_elaborate:
      s = data_elaborate[s]
    
    # If normalized language has this script suppressed, drop it
    if pn.plang is not None:
      if pn.plang in data_script:
        if data_script[pn.plang] == s:
          s = None
    
    # Add the normalized script if it wasn't suppressed
    if s is not None:
      if not pn.addSubtag('script', s):
        raise LogicError()
  
  # If region is present, determine normalized form
  if po.region is not None:
    # Get the current region setting
    r = po.region
    
    # If region is in elaboration dictionary, remap it
    if r in data_elaborate:
      r = data_elaborate[r]
    
    # Add the normalized region
    if not pn.addSubtag('region', r):
      raise LogicError()
  
  # If variant tags present, determine normalized forms
  vl = po.variant
  if vl is not None:
    # Add each normalized variant subtag
    for vt in vl:
      if vt in data_elaborate:
        vt = data_elaborate[vt]
      if not pn.addSubtag('variant', vt):
        raise LogicError()
  
  # We go the normalized tag, so return assembled, normalized form
  pn.complete()
  return pn.assemble()

# Check whether the given value is a valid, normalized language tag.
#
# EmbeddedParsingError is thrown if there was an error parsing any of
# the embedded data tables.
#
# You must normalize the language tag first using norm() because values
# that are not normalized will not validate.
#
# Parameters:
#
#   s : str | mixed - the value to check
#
# Return:
#
#   True if a valid and normalized language tag, False if not
#
def valid(s):

  # Check for embedded data tables
  if data_remap is None:
    raise EmbeddedParsingError()
  if data_langremap is None:
    raise EmbeddedParsingError()
  if data_langsimp is None:
    raise EmbeddedParsingError()
  if data_elaborate is None:
    raise EmbeddedParsingError()
  if data_script is None:
    raise EmbeddedParsingError()

  # Parameter must be a string
  if not isinstance(s, str):
    return False
  
  # Check length of language tag
  if (len(s) < 1) or (len(s) > 63):
    return False
  
  # Check that every character is ASCII alphanumeric or a hyphen, that
  # neither first nor last character is a hyphen, and that no hyphen is
  # immediately preceded by another hyphen
  for i in range(0, len(s)):
    
    # Get character code
    c = ord(s[i])
    
    # Check character code
    if ((c < ord('A')) or (c > ord('Z'))) and \
        ((c < ord('a')) or (c > ord('z'))) and \
        ((c < ord('0')) or (c > ord('9'))) and \
        (c != ord('-')):
      return False
    
    # Additional checks if hyphen
    if c == ord('-'):
      # Hyphen may be neither first nor last character
      if (i < 1) or (i >= len(s) - 1):
        return False
      
      # Hyphen may not be preceded by another hyphen
      if s[i - 1] == '-':
        return False
  
  # Split into subtags
  sl = s.split('-')
  
  # Check letter casing for all subtags
  singleton_found = False
  for x in range(0, len(sl)):
    
    # Handle the different cases
    if x < 1:
      # First subtag, so no uppercase letters allowed
      for c in sl[x]:
        if (ord(c) >= ord('A')) and (ord(c) <= ord('Z')):
          return False
      
    elif singleton_found:
      # Singleton has been encountered, so no uppercase letters
      # allowed
      for c in sl[x]:
        if (ord(c) >= ord('A')) and (ord(c) <= ord('Z')):
          return False
      
    elif (len(sl[x]) == 2) and sl[x].isalpha():
      # Two letters that are neither the first subtag nor after a
      # singleton, so must be two uppercase letters
      if not matchformat(sl[x], 'AA'):
        return False
      
    elif (len(sl[x]) == 4) and sl[x].isalpha():
      # Four letters that are neither the first subtag nor after a
      # singleton, so must be uppercase letter followed by lowercase
      # letters
      if not matchformat(sl[x], 'Aaaa'):
        return False
    
    elif (len(sl[x]) == 1):
      # First singleton found, so make sure not an uppercase letter and
      # set the singleton_found flag
      c = sl[x]
      if (ord(c) >= ord('A')) and (ord(c) <= ord('Z')):
        return False
      singleton_found = True
    
    else:
      # In all other cases, no uppercase letters allowed
      for c in sl[x]:
        if (ord(c) >= ord('A')) and (ord(c) <= ord('Z')):
          return False

  # If the whole tag is a GG2 or GG3 grandfathered tag, then tag is
  # valid and skip the rest of validation
  if (s == 'cel-gaulish') or (s == 'zh-min') or \
      (s == 'i-default') or (s == 'i-enochian') or (s == 'i-mingo'):
    return True
  
  # If the whole tag is a key in the remapping dictionary, then it is
  # either a GG1 grandfathered tag or legacy tag which are not allowed
  # in normalized language tags, so fail
  if s in data_remap:
    return False
  
  # Special case if first subtag is x
  if sl[0] == 'x':
    # In this special case, there must be at least two subtags
    if len(sl) < 2:
      return False
    
    # Also, all subtags must be at most eight characters
    for st in sl:
      if len(st) > 8:
        return False
    
    # If we got here in the special case, this language tag is valid
    return True

  # Check the first subtag, which is the primary language subtag since
  # we've handled all the special cases already -- begin by checking
  # that the first subtag is either two or three lowercase letters
  if (not matchformat(sl[0], 'aa')) and (not matchformat(sl[0], 'aaa')):
    return False
  
  # If there is a second subtag, it must not be three letters, because
  # secondary language extlangs are not allowed in normalized tags
  if len(sl) > 1:
    if (len(sl[1]) == 3) and sl[1].isalpha():
      return False
  
  # The primary language code may be neither in the language remapping
  # dictionary nor the simplification dictionary
  if (sl[0] in data_langremap) or (sl[0] in data_langsimp):
    return False
  
  # If there is a suppressed script, make sure the script isn't
  # specified
  if sl[0] in data_script:
    # Get the script that is suppressed for this language
    sn = data_script[sl[0]]
    
    # Scan for the script subtag
    for st in sl:
      # If this is a singleton, stop the search for script subtag
      # because only extension subtags and private subtags occur after
      # singletons
      if len(st) < 1:
        break
    
      # If this subtag matches the suppressed script, validation fails
      if st == sn:
        return False

  # We can now drop the validated primary language from the subtag list
  if len(sl) > 1:
    sl = sl[1:]
  else:
    sl = []
  
  # Check any private subtags
  prv_index = None
  for i in range(0, len(sl)):
    # Check if we are in private subtag range
    if prv_index is not None:
      # Private subtag range -- every subtag may have at most eight
      # characters
      if len(sl[i]) > 8:
        return False
      
    else:
      # Haven't found private subtag yet -- check current subtag
      if sl[i] == 'x':
        # Found the starting marker -- this must not be the last subtag
        if i >= len(sl) - 1:
          return False
        
        # Store the starting marker
        prv_index = i

  # Drop any private subtags now that they are validated
  if prv_index is not None:
    if prv_index > 0:
      sl = sl[0:prv_index]
    else:
      sl = []
  
  # Check any extension codes
  ext_index = None
  ext_current = None
  for x in range(0, len(sl)):
    # Check if this is an extension code
    if len(sl[x]) == 1:
      # Extension code -- if first one, record its index
      if ext_index is None:
        ext_index = x
      
      # If there is a previous code, make sure this one is not the same
      # and is in ascending order
      if ext_current is not None:
        if ord(ext_current) >= ord(sl[x]):
          return False
      
      # Update ext_current with the current extension code
      ext_current = sl[x]
      
      # The extension code must not be the last remaining subtag
      if x >= len(sl) - 1:
        return False
      
      # The next subtag must have at least two characters
      if len(sl[x + 1]) < 2:
        return False
    
    else:
      # Not an extension code -- if we are in extension code range, make
      # sure subtags are at most eight characters
      if ext_index is not None:
        if len(sl[x]) > 8:
          return False

  # Drop any extension codes now that they are validated
  if ext_index is not None:
    if ext_index > 0:
      sl = sl[0:ext_index]
    else:
      sl = []

  # Check that no remaining subtag is in the elaboration dictionary
  for st in sl:
    if st in data_elaborate:
      return False
  
  # If the first remaining subtag is a valid script tag, drop it
  if len(sl) > 0:
    if matchformat(sl[0], 'Aaaa'):
      if len(sl) > 1:
        sl = sl[1:]
      else:
        sl = []
  
  # If the first remaining subtag is a region tag, drop it
  if len(sl) > 0:
    if matchformat(sl[0], 'AA') or matchformat(sl[0], 'DDD'):
      if len(sl) > 1:
        sl = sl[1:]
      else:
        sl = []
  
  # Any remaining subtags must be variant tags
  for st in sl:
    # Variant tag is OK if five to eight characters
    if (len(st) >= 5) and (len(st) <= 8):
      continue
    
    # Variant tag is OK if four characters and first character is a
    # digit
    if len(st) == 4:
      if (ord(st[0]) >= ord('0')) and (ord(st[0]) <= ord('9')):
        continue
    
    # If we got here, variant tag has invalid format
    return False

  # If we got all the way here, language tag is valid and normalized
  return True

# Given a language tag or code, return the macrolanguage, if one is
# found.
#
# The passed language tag or code must pass valid() or a LogicError is
# thrown.
#
# EmbeddedParsingError is thrown if there was an error parsing any of
# the embedded data tables.
#
# The return value is the normalized language code for the
# macrolanguage, or None if there is no known macrolanguage.
#
# Parameters:
#
#   s : str - the valid, normalized language tag or code
#
# Return:
#
#   the macrolanguage code, or None if no macrolanguage
#
def macrolang(s):
  
  # Check for embedded data table
  if data_macro is None:
    raise EmbeddedParsingError()
  
  # Check parameter
  if not valid(s):
    raise LogicError()
  
  # Parse into subtags
  stl = s.split('-')
  
  # Look up first subtag for result
  if stl[0] in data_macro:
    return data_macro[stl[0]]
  else:
    return None
